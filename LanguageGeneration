The idea so far is to list out the states that Sophie is likely to be in, with new states added whenever a 
transition of a given confidence does not exist. These states are expected to be make intuitive sense, so that
we can label them later on. Or merge similar ones.

So states encode the mood and experience so far Sophie has encountered in the conversation. 
Each state has a list of training data on which a CFG/Markov Model is built, from which language generation takes place.

Emotions are fixed, we can encode fixed emotions - happy, sad, anger, witty, curious, etc. - 
best to keep 5-6 core emotions (such as FB/Portal/Slack). However, situations may vary.

Assume State 0-0 encodes greeting and happy. Let's say State 0-1 encodes greeting and say angry.

Let each word carry a transition probability, neutral words have a multiplying factor of 1, good have >1x, 
bad have <1x for a particular emotion. Therefore, any sentence will produce a value for each emotion, we use the
maximum of these to trigger the state transition.

Isn't a Markov chain essentially a non-deterministic CFG? Will check it out formally later.

Now the big question is how do we assign these values?
